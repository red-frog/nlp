## 注意力机制

- 是在序列到序列模型中用于注意力编码器状态的最常用方法, 它同时还可用于回顾序列模型的过去状态

- 不仅能用来处理编码器或前面的隐藏层,它同样还能用来获得其他特征的分布, 例如阅读理解任务中作为文本的词向量.

## 为什么需要注意力机制

- 减小处理高维输入数据的计算负担, 通过结构化的选取输入的子集, 降低数据维度.
- 让任务处理系统更专注于找到输入数据中显著的与当前输出相关的有用信息, 从而提高输出的质量

- Attention模型的最终目的是帮助类似编解码器这样的框架, 更好的学到多种内容模态之间的相互关系, 从而更好的表示这些信息, 克服其无法解释从而很难设计的缺陷