## 常用神经网络

#### CNN(卷积神经网络), 一种前馈神经网络, 包括卷积层和池化层
    - 图像相关(图像上色(老照片图片上色))
    - 灰度图像处理, 图像识别, 图像分类
    
#### RNN(循环神经网络), 一种节点定向连接成环的人工神经网络. 内部状态可以展示动态时序行为

- 说明以及用途
    - 处理文本相关
    - 语音相关
    - 比如:在线翻译, 聊天机器人
    
##### BP神经网络
    - 输入层
    - 隐藏层(3层左右比较好), 朴素贝叶斯
    - 输出层
    - 流程
        - 正向传播(输入-->隐含-->输出)
            - 网络初始化
            - 隐藏层的输出
            - 输出层的输出
        - 误差计算
        - 反向传播(修改权重, 使误差最小(求导或降维), 使用梯度?什么的算法)
            - 隐藏层到输出层
            - 输入层到隐藏层
        - 偏置更新
            - 隐藏层到输出层
            - 输入层到隐藏层
            
    - 特点
        - 逐层信息传递到最后输出
        - 沿着一条直线计算, 知道最后一层,求出计算结果
        - 包含输入.隐藏和输出层, 目的是实现从输入到输出的映射
        - 一般包含多层, 层与层之间全连接

------------------
-----------------------


##### 循环神经网络
- 特别之处是循环递归和递归参数(W), 相比较于BP神经网络
- 3大特性
   - 记忆特性
   - 接收2个输入(当前时刻的输入, 上一时刻的输出)
   - 参数共享

- 与经典网络的对比
    - 环和w参数
    
- 常见
    - one to one:
        - 同样维度的输入, 同样维度输出(分类问题)
        - demo:话的好坏
    - one to many
        - 图片的描述, 音乐的生成
    - many to one
        - 句子的处理, 输入, 多分类
        - 多个类别的样本, 对应一个输出
    - many to many
        - 输入和输出相同维度
            - 命名实体识别
        - 输入和输出不同维度
            - 翻译
            

##### 双向循环神经网络


- 每个时刻有两个隐藏层
- 一个从左到右, 一个从右到左
- 向前和向后传播参数独立
- 沿着时间事件进行展开(相同的W参数, 每次w会累计相乘)
    - W<1:梯度消失
    - W>1:梯度爆炸
    
 
------------------------
-----------------------

##### 梯度消失和梯度爆炸的解决

- 选择合适激活参数

    - Relu 函数, Relu函数的导数一直为1

- 选择合适参数初始化方法
    - ***[L]右上角, 幂***
    - W[L]=np.random.randn(shape[L])*0.01--->不建议(梯度消失)
        - w[l]是第L层的权重参数, shape是第L层权重参数矩阵的形状
    - W[L]=np.random.randn(shape[L])*np.sqrt(1/n[L-1])-------->建议(缓解梯度消失问题)
        - W[L]是第L层的权重参数, shape是第L层权重参数矩阵的形状, n[L-1]是L-1层神经元数
- 使用权重参数正则化
- 使用BatchNormalization
    - 通过规范化操作将输出信号x规范化到均值为0, 方差为1保证网络稳定性
    - 加大神经网络训练速度
    - 提高训练稳定性
    - 缓解梯度爆炸和消散问题
- 使用残差结构(几千层, 几百层神经网络)
    - 极大的提高了神经网络的深度
    - 很大程度上解决了梯度消散的问题
    - 允许训练很深层的网络
    - 可以看作解决梯度消散这个问题最重要,最有效的解决方式
- 使用梯度裁剪

```
if ||g|| > v 
g <---gv/||g||

其中v是梯度范数的上界, g用来更新参数的梯度

```    
            
---------------------
--------------------

        
#### LSTM(长短旗记忆网络---RNN的一种变体结构, 在其基础上增加了时间记忆),长短期记忆网络
    
- 说明以及用途
    - 合适处理和预测时间序列中间隔和延迟相对较长的重要事件
    - 聊天机器人, 长文本翻译, 自动写歌, 自动写诗
    